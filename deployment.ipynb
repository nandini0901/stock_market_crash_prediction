{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef04faed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded models and thresholds: RF=0.4, XGB=0.9987601960802718\n",
      "✅ Dataset loaded! Shape: (3646, 21)\n",
      "✅ Dropped rows with missing target.\n",
      "✅ Predictions added to dataset!\n",
      "   future_return    Close_y     High_y    Volume_x      Low_y       High_x  \\\n",
      "0       0.012348  20.040001  21.680000  3991400000  20.030001  1133.869995   \n",
      "1      -0.000264  19.350000  20.129999  2491020000  19.340000  1136.630005   \n",
      "2       0.007510  19.160000  19.680000  4972660000  18.770000  1139.189941   \n",
      "3       0.005930  19.059999  19.709999  5270680000  18.700001  1142.459961   \n",
      "4      -0.007817  18.129999  19.270000  4389590000  18.110001  1145.390015   \n",
      "\n",
      "        Open_x     Open_y      Close_x        Low_x  ...  \\\n",
      "0  1116.560059  21.680000  1132.989990  1116.560059  ...   \n",
      "1  1132.660034  20.049999  1136.520020  1129.660034  ...   \n",
      "2  1135.709961  19.590000  1137.140015  1133.949951  ...   \n",
      "3  1136.270020  19.680000  1141.689941  1131.319946  ...   \n",
      "4  1140.520020  19.270000  1144.979980  1136.219971  ...   \n",
      "\n",
      "   reddit_neutral_count  stock_tweets_total_posts  stock_tweets_avg_sentiment  \\\n",
      "0                   0.0                       0.0                         0.0   \n",
      "1                   0.0                       0.0                         0.0   \n",
      "2                   0.0                       0.0                         0.0   \n",
      "3                   0.0                       0.0                         0.0   \n",
      "4                   0.0                       0.0                         0.0   \n",
      "\n",
      "   stock_tweets_positive_count  stock_tweets_negative_count  Actual_is_crash  \\\n",
      "0                          0.0                          0.0                0   \n",
      "1                          0.0                          0.0                0   \n",
      "2                          0.0                          0.0                0   \n",
      "3                          0.0                          0.0                0   \n",
      "4                          0.0                          0.0                0   \n",
      "\n",
      "   RF_Crash_Probability  RF_Crash_Prediction  XGB_Crash_Probability  \\\n",
      "0              0.000398                    0               0.000847   \n",
      "1              0.000349                    0               0.000835   \n",
      "2              0.000398                    0               0.000851   \n",
      "3              0.000349                    0               0.000850   \n",
      "4              0.000398                    0               0.000848   \n",
      "\n",
      "   XGB_Crash_Prediction  \n",
      "0                     0  \n",
      "1                     0  \n",
      "2                     0  \n",
      "3                     0  \n",
      "4                     0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "✅ Results saved as 'deployment_predictions.csv'\n",
      "\n",
      "📊 Prediction Summary:\n",
      "RF_Crash_Prediction  XGB_Crash_Prediction\n",
      "0                    0                       3570\n",
      "1                    1                         72\n",
      "                     0                          4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 📦 Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 📥 Load the tuned models and thresholds\n",
    "tuned_rf = joblib.load('calibrated_random_forest_model.pkl')\n",
    "tuned_xgb = joblib.load('calibrated_xgboost_model.pkl')\n",
    "thresholds = joblib.load('optimal_thresholds.pkl')  # Contains {'rf': 0.40, 'xgb': 1.0}\n",
    "\n",
    "rf_threshold = thresholds['rf']\n",
    "xgb_threshold = thresholds['xgb']\n",
    "\n",
    "print(f\"✅ Loaded models and thresholds: RF={rf_threshold}, XGB={xgb_threshold}\")\n",
    "\n",
    "# 📂 Load user dataset\n",
    "data_path = \"D:/stock_market_crash_prediction/data/processed/merged_data_top20_features.csv\"  # Replace with your file\n",
    "data = pd.read_csv(data_path)\n",
    "print(f\"✅ Dataset loaded! Shape: {data.shape}\")\n",
    "\n",
    "# 🎯 Drop rows where target is missing (if needed)\n",
    "if 'is_crash' in data.columns:\n",
    "    data.dropna(subset=['is_crash'], inplace=True)\n",
    "    print(\"✅ Dropped rows with missing target.\")\n",
    "\n",
    "# 🧹 Separate features and target\n",
    "if 'is_crash' in data.columns:\n",
    "    X = data.drop(columns=['is_crash'])\n",
    "    y = data['is_crash']\n",
    "else:\n",
    "    X = data.copy()\n",
    "    y = None\n",
    "\n",
    "# 🧽 Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# 🔮 Get predicted probabilities\n",
    "rf_probs = tuned_rf.predict_proba(X_imputed)[:, 1]\n",
    "xgb_probs = tuned_xgb.predict_proba(X_imputed)[:, 1]\n",
    "\n",
    "# 🏁 Apply thresholds for final predictions\n",
    "rf_preds = (rf_probs >= rf_threshold).astype(int)\n",
    "xgb_preds = (xgb_probs >= xgb_threshold).astype(int)\n",
    "\n",
    "# 📊 Add predictions and probabilities to the dataset\n",
    "results_df = X.copy()\n",
    "if y is not None:\n",
    "    results_df['Actual_is_crash'] = y\n",
    "\n",
    "results_df['RF_Crash_Probability'] = rf_probs\n",
    "results_df['RF_Crash_Prediction'] = rf_preds\n",
    "results_df['XGB_Crash_Probability'] = xgb_probs\n",
    "results_df['XGB_Crash_Prediction'] = xgb_preds\n",
    "\n",
    "print(\"✅ Predictions added to dataset!\")\n",
    "print(results_df.head())\n",
    "\n",
    "# 💾 Save results\n",
    "results_df.to_csv(\"deployment_predictions.csv\", index=False)\n",
    "print(\"✅ Results saved as 'deployment_predictions.csv'\")\n",
    "\n",
    "# Optional summary\n",
    "print(\"\\n📊 Prediction Summary:\")\n",
    "print(results_df[['RF_Crash_Prediction', 'XGB_Crash_Prediction']].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04445be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('D:/stock_market_crash_prediction/notebooks/deployment_predictions.csv').head(100)\n",
    "sample.to_csv('D:/stock_market_crash_prediction/data/sample_input.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb30a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
